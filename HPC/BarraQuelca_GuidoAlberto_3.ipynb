{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BarraQuelca_GuidoAlberto_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guidobarra/pyhton-GPU/blob/main/HPC/BarraQuelca_GuidoAlberto_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "# 1 Introducción\n",
        "\n",
        "El siguiente ejemplo se realizara la **Adición Matricial** A y B, el resultado de la Adición se guardara en la matriz C.\n",
        "Hay varias definiciones de Adición Matricial, por mencionar algunos:\n",
        "\n",
        "**Suma:** denotada por el signo +, suma el componente de la matriz A y el componente de la matriz B y el resultado de esta suma es un componente de la matriz C. Realiza la suma componente a componente de las matrices.\n",
        "\n",
        "**Suma Directa**: denotada por ⊕, no suma componente a componente como la Suma, sino que ambas matrices conviven en una matriz C de mayor dimensión que la matrices A Y B. Cada componente de la diagonal principal de la matriz C es una matriz, el resto de los componentes tiene ceros. Esta definición de Adición no necesita que sus matrices tengan las mismas dimensiones.\n",
        "\n",
        "En este ejemplo se realizará la Adición Matricial de **Suma**, la cual es la más conocida y más utilizada. Como se explicó antes la Adición Matricial de **Suma** realiza la suma componente a componente de las matrices, además de esto las matrices deben tener las mismas dimensiones, si las dimensiones no son igual no se puede realizar la **Suma**\n",
        "\n",
        "El desarrollo teórico de la **Suma** de matrices se mostrará a continuación. Realiza la suma componente a componente de las matrices\n",
        "\n",
        "\\begin{aligned}\\mathbf {A} +\\mathbf {B} &={\\begin{bmatrix}a_{11}&a_{12}&\\cdots &a_{1n}\\\\a_{21}&a_{22}&\\cdots &a_{2n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\a_{m1}&a_{m2}&\\cdots &a_{mn}\\\\\\end{bmatrix}}+{\\begin{bmatrix}b_{11}&b_{12}&\\cdots &b_{1n}\\\\b_{21}&b_{22}&\\cdots &b_{2n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\b_{m1}&b_{m2}&\\cdots &b_{mn}\\\\\\end{bmatrix}}\\\\&={\\begin{bmatrix}a_{11}+b_{11}&a_{12}+b_{12}&\\cdots &a_{1n}+b_{1n}\\\\a_{21}+b_{21}&a_{22}+b_{22}&\\cdots &a_{2n}+b_{2n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\a_{m1}+b_{m1}&a_{m2}+b_{m2}&\\cdots &a_{mn}+b_{mn}\\\\\\end{bmatrix}}\\\\\\end{aligned}\n",
        "\n",
        "\n",
        "La condición para poder realizar la suma de matrices es que la cantidad de filas de la matriz A tiene que ser igual a la cantidad de filas de la matriz B, y además cantidad de columnas de la matriz A tiene que ser igual a la cantidad de columnas de la matriz B, en la imagen de arriba se ve como la matriz A y B cumple con esta condición.\n",
        "\n",
        "EL objetivo es enseñar el funcionamiento del Lenguaje Python, C++, OpenMP y el manejo de la operación de matriz a bajo nivel. El ejemplo es ilustrativo para entender y utilizar los Core que tiene un procesador, realizar proceso en paralelo y sacar conclusiones de la biblioteca OpenMP programar un código que se va a realizar de forma paralela en los Core del procesador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "# 2 Armado del ambiente\n",
        "Se crea un archivo .cpp con el nombre de suma_matriz_axpy, este archivo contiene el codigo él cual ejecutará la suma de matrices de forma secuencial y tambien la suma de matrices de forma paralela utilizando los Core que tiene el procesador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJr_9dXGpJ05"
      },
      "source": [
        "# Codigo C++.\n",
        "code = \"\"\"\n",
        "// Axpy con OpenMP, usando C++, ejecutado en Colab. \n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cstdlib>\n",
        "#include <sys/time.h>\n",
        "#include <omp.h>    // Cabecera OpenMP   \n",
        "\n",
        "// ----------------------------------------------------------------------------\n",
        "// Macros que miden el tiempo.\n",
        "\n",
        "static double dHashTiempoHistory[3];\n",
        "static struct timeval tv;\n",
        "\n",
        "#define TIEMPO_INI( h )      \\\n",
        "   gettimeofday(&tv,NULL);   \\\n",
        "   dHashTiempoHistory[ h ] = tv.tv_sec + tv.tv_usec/1000000.0;\n",
        "   \n",
        "   \n",
        "#define TIEMPO_FIN( h )      \\\n",
        "   gettimeofday(&tv,NULL);   \\\n",
        "   dHashTiempoHistory[ h ] = ((tv.tv_sec + tv.tv_usec/1000000.0) - dHashTiempoHistory[ h ]) * 1000; // Devuelvo en milisegundos\n",
        "#define TIEMPO_GET( h ) dHashTiempoHistory[ h ]\n",
        "\n",
        "#define HTH_TOTAL         1\n",
        "#define HTH_AXPY_SEC      2\n",
        "#define HTH_AXPY_OMP      3\n",
        "\n",
        "// ----------------------------------------------------------------------------\n",
        "\n",
        "int main(int argc, char* argv[]) \n",
        "{ \n",
        "  TIEMPO_INI( HTH_TOTAL )\n",
        "\n",
        "  // validar parametros.\n",
        "  if( argc != 4 )\n",
        "  {\n",
        "    std::cout<<argv[1]<<std::endl;\n",
        "    std::cout<<argv[2]<<std::endl;\n",
        "    std::cout<<argv[3]<<std::endl;\n",
        "    std::cerr<< \" Error en los parametros, los cantidad de parametros deben ser 3:\"<<std::endl<<\" (alfa), (beta), (Tamaño de la matriz cantidad_N).\"<<argc<<std::endl;\n",
        "    exit( -1 );\n",
        "  }\n",
        "\n",
        "  // Obtener parametros\n",
        "  float alfa     = atof( argv[1] );\n",
        "  float beta     = atoi( argv[2] );\n",
        "  int cantidad_N = atoi( argv[3] );\n",
        "  \n",
        "  // Defino la memoria de las Matriz A, B y C. Inicializo con unos la matriz A y con el numero dos la matriz B\n",
        "  std::vector<std::vector<double>> matriz_A(cantidad_N, std::vector<double> (cantidad_N, 1));\n",
        "  std::vector<std::vector<double>> matriz_B(cantidad_N, std::vector<double> (cantidad_N, 2));\n",
        "  std::vector<std::vector<double>> matriz_C_secuencial(cantidad_N, std::vector<double> (cantidad_N, 0));\n",
        "  std::vector<std::vector<double>> matriz_C_paralela(cantidad_N, std::vector<double> (cantidad_N, 0));\n",
        "\n",
        "  // Realizo la función Axpy en forma secuencial.\n",
        "\n",
        "  TIEMPO_INI( HTH_AXPY_SEC )\n",
        "\n",
        "  for (int i=0;i<cantidad_N;i++)\n",
        "  {\n",
        "    for (int j=0;j<cantidad_N;j++)\n",
        "    {\n",
        "      matriz_C_secuencial[i][j] = alfa*matriz_A[i][j] + beta*matriz_B[i][j];\n",
        "    }\n",
        "  }\n",
        "\n",
        "  TIEMPO_FIN( HTH_AXPY_SEC )\n",
        "\n",
        "\n",
        "  // Realizo la función Axpy con OpenMP, paralela.\n",
        "\n",
        "  TIEMPO_INI( HTH_AXPY_OMP )\n",
        "\n",
        "  for (int i=0;i<cantidad_N;i++)\n",
        "  {  \n",
        "    #pragma omp parallel for  \n",
        "    for (int j=0;j<cantidad_N;j++)\n",
        "    {\n",
        "      matriz_C_paralela[i][j] = alfa*matriz_A[i][j] + beta*matriz_B[i][j];\n",
        "    }\n",
        "  }\n",
        "\n",
        "  TIEMPO_FIN( HTH_AXPY_OMP )\n",
        "\n",
        "  // --------------------------------------------\n",
        "  // Muestro los resultados.\n",
        "  /*\n",
        "  std::cout<<\" matriz paralela :\"<<std::endl;\n",
        "  std::cout<<\"[\"; \n",
        "  for(int i=0;i<cantidad_N;i++)\n",
        "  {\n",
        "    for(int c=0;c<cantidad_N;c++)\n",
        "    {\n",
        "      std::cout<<matriz_C_paralela[i][c]<< \", \";\n",
        "    }\n",
        "    std::cout<<std::endl;\n",
        "  }\n",
        "  std::cout<<\"]\"<<std::endl<<std::endl; \n",
        "\n",
        "  std::cout<<\" matriz secuencial :\"<<std::endl;\n",
        "  std::cout<<\"[\"; \n",
        "  for(int i=0;i<cantidad_N;i++)\n",
        "  {\n",
        "    for(int c=0;c<cantidad_N;c++)\n",
        "    {\n",
        "      std::cout<<matriz_C_secuencial[i][c]<< \", \";\n",
        "    }\n",
        "    std::cout<<std::endl;\n",
        "  }\n",
        "  std::cout<<\"]\"<<std::endl; \n",
        "  */\n",
        "\n",
        "  TIEMPO_FIN( HTH_TOTAL )\n",
        "\n",
        " std::cout<<\"EJERCICIO DE SUMA DE MATRICES\"<<std::endl;\n",
        " std::cout<<\"C = alfa*A + beta*B\"<<std::endl;\n",
        " std::cout<<\"se realizo \"<<cantidad_N*cantidad_N<<\" operaciones de suma\"<<std::endl;\n",
        " std::cout<<\"Valor ALFA       : \"<<alfa<<std::endl;\n",
        " std::cout<<\"Valor BETA       : \"<<beta<<std::endl;\n",
        " std::cout<<\"MATRIZ CUADRADA  : \"<<cantidad_N<<std::endl; \n",
        " std::cout<<\"Valores Reales   : \"<<std::endl;\n",
        " std::cout<<\"Tiempo TOTAL     : \"<<TIEMPO_GET(HTH_TOTAL   )<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Sec  : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Omp  : \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<std::endl;\n",
        " std::cout<<\"SpeedUp          : (tiempo Secuencial/tiempo paralelo) : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" / \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Eficiencia       : SpeedUp/nro procesadores            : \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<\" / \"<<omp_get_num_procs()<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))<<std::endl;\n",
        " std::cout<<\"Coste Sec        : nro procesadores*Tiempo             : \"<<1<<\" * \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        " std::cout<<\"Coste Omp        : nro procesadores*Tiempo             : \"<<omp_get_num_procs()<<\" * \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Funcion Overhead : Coste Omp - tiempo Secuencial       : \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<\" - \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))-TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        "\n",
        "\n",
        " std::cout<<std::endl;\n",
        " std::cout<<\"Valores Ideal: \"<<std::endl;\n",
        " TIEMPO_GET(HTH_AXPY_OMP) = TIEMPO_GET(HTH_AXPY_SEC) / 2;\n",
        " std::cout<<\"Tiempo axpy Sec  : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Omp  : \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" [ms]\"<<std::endl;\n",
        "\n",
        " std::cout<<\"SpeedUp          : (tiempo Secuencial/tiempo paralelo) : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" / \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Eficiencia       : SpeedUp/nro procesadores            : \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<\" / \"<<omp_get_num_procs()<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))<<std::endl;\n",
        " std::cout<<\"Coste Sec        : nro procesadores*Tiempo             : \"<<1<<\" * \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        " std::cout<<\"Coste Omp        : nro procesadores*Tiempo             : \"<<omp_get_num_procs()<<\" * \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Funcion Overhead : Coste Omp - tiempo Secuencial       : \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<\" - \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))-TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        "\n",
        "\n",
        "}\n",
        "// ----------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"\n",
        "text_file = open(\"suma_matriz_axpy.cpp\", \"w\")\n",
        "text_file.write(code)\n",
        "text_file.close()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Peywru5zTyny"
      },
      "source": [
        "#@title # 2.1 Parámetros de ejecución\n",
        "#@markdown ### Especifique las dimensiones de la matrices:\n",
        "\n",
        "try: \n",
        "  tam_matriz =  4#@param {type:\"integer\"}\n",
        "  alfa =  1#@param {type:\"integer\"}\n",
        "  beta =  2#@param {type:\"integer\"}\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"Error de ingresar los parametros\")\n",
        "  print(\"Error debido a: \", e.__class__)\n",
        "  print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "## 2.2 Compila el codigo de C++."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gE-Ez1qtyIA"
      },
      "source": [
        "!g++ -o suma_matriz -fopenmp suma_matriz_axpy.cpp"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "# 3 Desarrollo\n",
        "Ejecución del programa con OpenMP y Threading de python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my2uxMLFRM0Z"
      },
      "source": [
        "## 3.1 Desarrollo OpenMP\n",
        "\n",
        "Ejecución del programa que realiza la suma de matrices utilizando OpenMP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiSh8sKbsX_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1eb2a7-6d6b-492f-fd13-35b27053c57c"
      },
      "source": [
        "try:\n",
        "  %env OMP_NUM_THREADS=2\n",
        "  !./suma_matriz 3 2 5000\n",
        "except Exception as e:\n",
        "  print(\"Oops Ocurrio una error!\")\n",
        "  print(\"Error debido a: \", e.__class__)\n",
        "  print(e)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: OMP_NUM_THREADS=2\n",
            "EJERCICIO DE SUMA DE MATRICES\n",
            "C = alfa*A + beta*B\n",
            "se realizo 25000000 operaciones de suma\n",
            "Valor ALFA       : 3\n",
            "Valor BETA       : 2\n",
            "MATRIZ CUADRADA  : 5000\n",
            "Valores Reales   : \n",
            "Tiempo TOTAL     : 1644.01 [ms]\n",
            "Tiempo axpy Sec  : 452.009 [ms]\n",
            "Tiempo axpy Omp  : 386.04 [ms]\n",
            "\n",
            "SpeedUp          : (tiempo Secuencial/tiempo paralelo) : 452.009 / 386.04 = 1.17089\n",
            "Eficiencia       : SpeedUp/nro procesadores            : 1.17089 / 2 = 0.585443\n",
            "Coste Sec        : nro procesadores*Tiempo             : 1 * 452.009 = 452.009\n",
            "Coste Omp        : nro procesadores*Tiempo             : 2 * 386.04 = 772.08\n",
            "Funcion Overhead : Coste Omp - tiempo Secuencial       : 772.08 - 452.009 = 320.071\n",
            "\n",
            "Valores Ideal: \n",
            "Tiempo axpy Sec  : 452.009 [ms]\n",
            "Tiempo axpy Omp  : 226.004 [ms]\n",
            "SpeedUp          : (tiempo Secuencial/tiempo paralelo) : 452.009 / 226.004 = 2\n",
            "Eficiencia       : SpeedUp/nro procesadores            : 2 / 2 = 1\n",
            "Coste Sec        : nro procesadores*Tiempo             : 1 * 452.009 = 452.009\n",
            "Coste Omp        : nro procesadores*Tiempo             : 2 * 226.004 = 452.009\n",
            "Funcion Overhead : Coste Omp - tiempo Secuencial       : 452.009 - 452.009 = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHBWan5J5ieB"
      },
      "source": [
        "## 3.2 Desarrollo Threading\n",
        "\n",
        "Ejecución del programa que realiza la suma de matrices utilizando el modulo threading de python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvoatw3r5i3Z",
        "outputId": "360adda8-a119-434b-e372-5316865d562d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "try:\n",
        "  import numpy as np\n",
        "  from numpy.testing import assert_array_equal\n",
        "  import threading\n",
        "  from datetime import datetime\n",
        "\n",
        "  # --------------------------------------------\n",
        "  # Definición de función que transforma el tiempo en  milisegundos \n",
        "  tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "  # --------------------------------------------\n",
        "\n",
        "\n",
        "  #Defino funciones\n",
        "\n",
        "  #Suma elemento a elemento de la matriz\n",
        "  def sumaElemento(a, b, c, alfa, beta, fila):\n",
        "    c[fila] = alfa*a + beta*b\n",
        "  \n",
        "  #Suma de matrices utilizando tam hilos\n",
        "  def sumaMatrizParelela(matriz_a, matriz_b, tam, alfa, beta, func=sumaElemento):\n",
        "    \n",
        "    #cantidad de hilos o jobs\n",
        "    print('ejecutando {} jobs en paralelo'.format(tam))\n",
        "  \n",
        "    matriz_c_paralela = np.zeros((tam, tam), dtype=int)\n",
        "\n",
        "    #array de hilos\n",
        "    threads = []\n",
        "\n",
        "    for i in range(tam):\n",
        "      #configuracion de hilo, funcion a ejecutar y parametros de la funcion\n",
        "      th = threading.Thread(target=func, \n",
        "                            args=(matriz_a[i], \n",
        "                                  matriz_b[i],\n",
        "                                  matriz_c_paralela,\n",
        "                                  alfa,\n",
        "                                  beta,\n",
        "                                  i)\n",
        "                            )\n",
        "      #ejecutar hilo\n",
        "      th.start()\n",
        "      #guardar hilo en array\n",
        "      threads.append(th)\n",
        "  \n",
        "    #espero a que termine todos los hilos\n",
        "    for th in threads:\n",
        "        th.join()\n",
        "\n",
        "    return matriz_c_paralela\n",
        "  \n",
        "  def sumaMatrizSecuencial(matriz_a, matriz_b, tam, alfa, beta):\n",
        "    matriz_c_secuencial = np.zeros((tam, tam), dtype=int)\n",
        "    for i in range(tam):\n",
        "      for j in range(tam):\n",
        "        matriz_c_secuencial[i][j] = alfa*matriz_a[i][j] + beta*matriz_b[i][j]\n",
        "\n",
        "    return matriz_c_secuencial\n",
        "  \n",
        "  if __name__ == '__main__':\n",
        "         \n",
        "    cant = tam_matriz\n",
        "\n",
        "    tiempo_definicion_matrices = datetime.now()\n",
        "\n",
        "    #defino matrices A, B\n",
        "    a = np.ones((cant, cant), dtype=int)\n",
        "    b = np.ones((cant, cant), dtype=int)*2\n",
        "\n",
        "    tiempo_definicion_matrices = datetime.now() - tiempo_definicion_matrices\n",
        "\n",
        "    tiempo_suma_secuencial = datetime.now()\n",
        "\n",
        "    matriz_c_secuencial = sumaMatrizSecuencial(a, b, cant, alfa, beta)\n",
        "\n",
        "    tiempo_suma_secuencial = datetime.now() - tiempo_suma_secuencial\n",
        "\n",
        "    tiempo_suma_paralela = datetime.now()\n",
        "\n",
        "    matriz_c_paralela = sumaMatrizParelela(a, b, cant, alfa, beta)\n",
        "\n",
        "    tiempo_suma_paralela = datetime.now() - tiempo_suma_paralela\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\n**SUMA DE MATRICES**\\n\")\n",
        "    print(\"Tiempo de definicion de matrices: \", tiempo_en_ms( tiempo_definicion_matrices ), \"[ms]\" )\n",
        "    print(\"Tiempo suma secuencial: \", tiempo_en_ms( tiempo_suma_secuencial ), \"[ms]\" )\n",
        "    print(\"Tiempo suma paralela: \", tiempo_en_ms( tiempo_suma_paralela ), \"[ms]\" )\n",
        "    print(\"Matiz A:\\n\", a)\n",
        "    print(\"Matiz B:\\n\", b)\n",
        "    print(\"Matiz secuencial C:\\n\", matriz_c_secuencial)\n",
        "    print(\"Matiz paralela C:\\n\", matriz_c_paralela)\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"Oops Ocurrio una error!\")\n",
        "  print(\"Error debido a: \", e.__class__)\n",
        "  print(e)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ejecutando 5000 jobs en paralelo\n",
            "\n",
            "**SUMA DE MATRICES**\n",
            "\n",
            "Tiempo de definicion de matrices:  571.854 [ms]\n",
            "Tiempo suma secuencial:  36426.92 [ms]\n",
            "Tiempo suma paralela:  1213.401 [ms]\n",
            "Matiz A:\n",
            " [[1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " ...\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]]\n",
            "Matiz B:\n",
            " [[2 2 2 ... 2 2 2]\n",
            " [2 2 2 ... 2 2 2]\n",
            " [2 2 2 ... 2 2 2]\n",
            " ...\n",
            " [2 2 2 ... 2 2 2]\n",
            " [2 2 2 ... 2 2 2]\n",
            " [2 2 2 ... 2 2 2]]\n",
            "Matiz secuencial C:\n",
            " [[7 7 7 ... 7 7 7]\n",
            " [7 7 7 ... 7 7 7]\n",
            " [7 7 7 ... 7 7 7]\n",
            " ...\n",
            " [7 7 7 ... 7 7 7]\n",
            " [7 7 7 ... 7 7 7]\n",
            " [7 7 7 ... 7 7 7]]\n",
            "Matiz paralela C:\n",
            " [[7 7 7 ... 7 7 7]\n",
            " [7 7 7 ... 7 7 7]\n",
            " [7 7 7 ... 7 7 7]\n",
            " ...\n",
            " [7 7 7 ... 7 7 7]\n",
            " [7 7 7 ... 7 7 7]\n",
            " [7 7 7 ... 7 7 7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "---\n",
        "# 4 Tabla de pasos\n",
        "\n",
        "\n",
        " Procesador | lengueaje   | Funciòn \t\t\t\t\t   | Detalle\n",
        "------------|----------   |--------------------------------|----------------\n",
        "CPU         | Python      |  open()                        | Abrir un archivo para escritura\n",
        "CPU         | Python      |  write()                       | Escribir el archivo\n",
        "CPU         | Python      |  close()                       | Cerrar el archivo\n",
        "CPU   \t    | Python      |  !g++ -o obj -fopenmp c.cpp    | Compilar el archivo .cpp, y crear ejectable\n",
        "CPU         | Python      |  %env OMP_NUM_THREADS=n        | Cantidad de threads n\n",
        "CPU         | Python      |  !./suma_matriz 2 5 18000      | Ejecutar el programa openMP\n",
        "CPU         | C++         |  TIEMPO_INI()                  | Inicio del tiempo\n",
        "CPU         | C++         |  TIEMPO_FIN()                  | Finaliza el tiempo\n",
        "CPU         | C++         |  TIEMPO_GET()                  | Obtener el tiempo guardado\n",
        "CPU         | C++, openMP |  omp_get_num_procs()           | Obtener la cantidad de procesadores\n",
        "CPU         | C++, openMP |  omp_get_thread_num()          | Obtener numero del hilo\n",
        "CPU\t\t    | C++, openMP |  #pragma omp parallel for      | Crear los hilos en base a la sentencia for\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ9i7KaUsHm6"
      },
      "source": [
        "#5 Conclusiones\n",
        "\n",
        "Se realizaron varias pruebas con matrices de distintos tamaños. Colab nos brinda un procesador y una memoria fijas, el cual nos limita al momento de realizar las pruebas, un ejemplo de esto es que no se puede probar matrices mayores a 18000x18000, debido a que se llena la menoria que nos ofrece Colab.\n",
        "\n",
        "**Pruebas con Cantidad_N<1000:** En estas pruebas se observó que el tiempo de ejecución para la suma de matrices son aproximadamente igual para Cantidad_N = 1000, tanto para la forma secuencial, como para la forma paralela que utiliza los Core del procesador. Al disminuir la Cantidad_N el tiempo de ejecución de la forma secuencial es mejor que el tiempo de ejecución de la forma paralela esto es debido a que openMP utiliza hilos, la creación de los hilos y su cambio de contexto hacen que el tiempo que ejecución del algoritmo aumente.\n",
        "\n",
        "**Pruebas con Cantidad_N>1000:** En estas pruebas se observo que el tiempo de ejecución para la suma de matrices son distintos, al utilizar los Core del procesador se observa que hay una mejora en la eficiencia y el tiempo es menor, en comparación con la forma secuencial.\n",
        "\n",
        "**Pruebas variando la cantidad de hilos:** En esta prueba se observo un baja significativa de la performance del 30% o mayor, en comparación con la forma secuencial, al aumentar la cantidad de hilos el tiempo de ejecución de la forma paralela aumenta, esto es debido a que el tiempo de creación de los hilos y su cambio de contexto impacta en el tiempo total, si bien openMP mejora y reduce el tiempo de creacion y cambio de contexto de los hilos, al tener varios hilos el tiempo aumenta.\n",
        "\n",
        "Se concluye que la cantidad de elementos, los hilos y los Core del procesador son factores que influyen en el tiempo de ejecución del algoritmo. Estos tres factores son importantes y hay que tenerlos en cuenta debido a que el tiempo de ejecución utilizando openMP es peor que la ejecución secuencial si se tiene un conjunto pequeño de elementos a procesar o si se tiene muchos hilos con un procesador que tiene pocos Core. Para un conjunto grande de elementos y una cantidad de hilos acorde a la cantidad de Core del procesador el tiempo que ejecución del algoritmo utilizando openMP es mejor que el tiempo de ejecución secuencial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOQYEPGtsPfL"
      },
      "source": [
        "---\n",
        "# 6 Bibliografía\n",
        "\n",
        "[1] Suma de matrices, conceptual: [Pagina economipedia](https://economipedia.com/definiciones/suma-de-matrices.html)\n",
        "\n",
        "[2] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n",
        "\n",
        "[3] Adicíon Matricial: [WIKI](https://es.wikipedia.org/wiki/Adici%C3%B3n_matricial)\n",
        "\n",
        "[4] OpenMP: [PDF](http://so-unlam.com.ar/material-clase/HPC/openmp-4.5.pdf)\n",
        "\n",
        "[5] MARKDOWN SYNTAX Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[6] Función Axpy de biblioteca BLAS: [Referencia](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-axpy.html)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}