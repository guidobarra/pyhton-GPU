{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiplicacion_matrices_GPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guidobarra/pyhton-GPU/blob/main/multiplicacion_matrices_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoYPFWcielY3"
      },
      "source": [
        "# 1 Introducción\n",
        "\n",
        "El siguiente ejemplo se multiplicara dos matrices A y B, el resultado de la multiplicacion se guardara en la matriz de resultado C\n",
        "C=AB\\begin{pmatrix}a_{11}&\\cdots &a_{1n}\\\\\\vdots &\\ddots &\\vdots \\\\a_{m1}&\\cdots &a_{mn}\\end{pmatrix}\\begin{pmatrix}b_{11}&\\cdots &b_{1p}\\\\\\vdots &\\ddots &\\vdots \\\\b_{n1}&\\cdots &b_{np}\\end{pmatrix}\\begin{pmatrix}a_{11}b_{11}+\\cdots +a_{1n}b_{n1}&\\cdots &a_{11}b_{1p}+\\cdots +a_{1n}b_{np}\\\\\\vdots &\\ddots &\\vdots \\\\a_{m1}b_{11}+\\cdots +a_{mn}b_{n1}&\\cdots &a_{m1}b_{1p}+\\cdots +a_{mn}b_{np}\\end{pmatrix}\n",
        "\n",
        "\n",
        "EL objetivo es enseñar el funcionamiento del Lenguaje Python, CUDA y el manejo de la operacion de matriz a bajo nivel. El ejemplo es ilustrativo para entededer los multi hilos de la GPU en dos dimenciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32YB71STfPcy"
      },
      "source": [
        "---\n",
        "# 2 Armado del ambiente\n",
        "Toma la direcciòn web de una imagen con  acceso público en internet, la deja disponible al contexto de ejecuciòn del cuaderno colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcnL4UkAN7ub"
      },
      "source": [
        "#@title # 2.1 Parámetros de ejecución\n",
        "#@markdown ### Especifique las dimeciones de la matrices:\n",
        "\n",
        "try: \n",
        "  fila_mat_a =  250#@param {type:\"integer\"}\n",
        "  colum_mat_a =  250#@param {type:\"integer\"}\n",
        "\n",
        "  fila_mat_b =  250#@param {type:\"integer\"}\n",
        "  colum_mat_b =  250#@param {type:\"integer\"}\n",
        "\n",
        "except:\n",
        "  print(\"Error de ingresar los parametros\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-KdeQaNvHyx"
      },
      "source": [
        "Validar las matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paAPWUM4vICC"
      },
      "source": [
        "#A.B\n",
        "if fila_mat_a < 0 or colum_mat_a < 0:\n",
        "  print(\"ERROR LAS DIMENCIONES DE LA MATRIZ A TIENE QUE SER MAYOR A 0\")\n",
        "if fila_mat_b < 0 or colum_mat_b < 0:\n",
        "  print(\"ERROR LAS DIMENCIONES DE LA MATRIZ B TIENE QUE SER MAYOR A 0\")\n",
        "if colum_mat_a != fila_mat_b:\n",
        "  print(\"ERROR LAS DIMENCIONES DE LAS MATRIZ NO PERMITEN REALIZAR LA MULTIPLICACION\")"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GLsQ34ysP4_"
      },
      "source": [
        "---\n",
        "## 2.2 Instala en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ropgS48tsRTv",
        "outputId": "24a25de9-caed-4d49-9f28-e25d76ff66ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.6/dist-packages (2020.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.1.3)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.6/dist-packages (from pycuda) (2020.4.3)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: dataclasses>=0.7; python_version <= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt4Pea0Psrx_"
      },
      "source": [
        "---\n",
        "# 3 Desarrollo\n",
        "Ejecución del algoritmo escala de grises en GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_uVXVJjz_Jr",
        "outputId": "5adca1d8-6f35-4cba-da41-6e06b4680134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from datetime import datetime\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "import numpy\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from   pycuda.compiler import SourceModule\n",
        "\n",
        "# --------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "# --------------------------------------------\n",
        "\n",
        "tiempo_definicion_matrices = datetime.now()\n",
        "\n",
        "# CPU - Defino la memoria de la matriz A en cpu.\n",
        "matriz_a = numpy.random.randn(fila_mat_a, colum_mat_a)*10\n",
        "matriz_a = matriz_a.astype(numpy.int32())\n",
        "\n",
        "# CPU - Defino la memoria de la matriz B en cpu.\n",
        "matriz_b = numpy.random.randn(fila_mat_b, colum_mat_b)*10\n",
        "matriz_b = matriz_b.astype(numpy.int32())\n",
        "\n",
        "# CPU - Defino la memoria de la matriz resultado C en cpu.\n",
        "matriz_c = numpy.random.randn(fila_mat_a, colum_mat_b)*0\n",
        "matriz_c = matriz_c.astype(numpy.int32())\n",
        "matriz_c_secuencial = numpy.random.randn(fila_mat_a, colum_mat_b)*0\n",
        "matriz_c_secuencial = matriz_c_secuencial.astype(numpy.int32())\n",
        "\n",
        "tiempo_definicion_matrices = datetime.now() - tiempo_definicion_matrices\n",
        "\n",
        "tiempo_multiplicacion_secuencial = datetime.now()\n",
        "\n",
        "for f in range(fila_mat_a):\n",
        "  for c in range(colum_mat_b):\n",
        "    for inter in range(colum_mat_a):\n",
        "      matriz_c_secuencial[f][c] += matriz_a[f][inter]*matriz_b[inter][c]\n",
        "\n",
        "tiempo_multiplicacion_secuencial = datetime.now() - tiempo_multiplicacion_secuencial\n",
        "    \n",
        "\n",
        "tiempo_reserva_memoria_GPU = datetime.now()\n",
        "# CPU - reservo la memoria GPU.\n",
        "matriz_a_Gpu = cuda.mem_alloc(matriz_a.nbytes)\n",
        "matriz_b_Gpu = cuda.mem_alloc(matriz_b.nbytes)\n",
        "matriz_c_Gpu = cuda.mem_alloc(matriz_c.nbytes)\n",
        "tiempo_reserva_memoria_GPU = datetime.now() - tiempo_reserva_memoria_GPU\n",
        "\n",
        "tiempo_copia_memoria_GPU = datetime.now()\n",
        "# GPU - Copio la memoria al GPU.\n",
        "cuda.memcpy_htod(matriz_a_Gpu, matriz_a)\n",
        "cuda.memcpy_htod(matriz_b_Gpu, matriz_b)\n",
        "cuda.memcpy_htod(matriz_c_Gpu, matriz_c)\n",
        "tiempo_copia_memoria_GPU = datetime.now() - tiempo_copia_memoria_GPU\n",
        "\n",
        "#CPU - Defino la funcion kernel que ejecutará en GPU\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void multiplicar(int ancho, int alto, int inter, int *matriz_a , int *matriz_b, int *matriz_c)\n",
        "{\n",
        "    // Calculo las coordenadas del Thread en dos dimensiones.\n",
        "    int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    int idy = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "    \n",
        "    // Verifico que los Thread, esten dentro de las dimensiones de la imagen.\n",
        "    if( idx < ancho && idy < alto ) {\n",
        "      int indice = idy+(idx*ancho);\n",
        "      int i = 0;\n",
        "      int resul = 0;\n",
        "\n",
        "      //\n",
        "      while (i<inter) {\n",
        "        //multiplico fila por columna y sumo el resultado de cada componente\n",
        "        resul += matriz_a[idx*inter + i]*matriz_b[idy + i*inter];\n",
        "        i++;\n",
        "      }\n",
        "      //paso el resultado obtenido a la componente de la matriz\n",
        "      matriz_c[indice] = resul;\n",
        "    }\n",
        "}\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "# CPU - Genero la función kernel.\n",
        "kernel = module.get_function(\"multiplicar\")\n",
        "\n",
        "dim_hilo_x = 16\n",
        "dim_bloque_x = numpy.int( (fila_mat_a+dim_hilo_x-1) / dim_hilo_x )\n",
        "\n",
        "dim_hilo_y = 19\n",
        "dim_bloque_y = numpy.int( (colum_mat_b+dim_hilo_y-1) / dim_hilo_y )\n",
        "\n",
        "print( \"Thread: [\", \n",
        "      dim_hilo_x, \n",
        "      \",\", \n",
        "      dim_hilo_y, \n",
        "      \" ], Bloque : [\", \n",
        "      dim_bloque_x, \n",
        "      \",\", \n",
        "      dim_bloque_y, \n",
        "      \"]\" )\n",
        "print( \"Total de Thread: [\", \n",
        "      dim_hilo_x*dim_bloque_x, \n",
        "      \",\", \n",
        "      dim_hilo_y*dim_bloque_y, \n",
        "      \" ]\", \n",
        "      \" = \", \n",
        "      dim_hilo_x*dim_bloque_x*dim_hilo_y*dim_bloque_y )\n",
        "\n",
        "tiempo_multiplicacion_paralela = datetime.now()\n",
        "\n",
        "kernel( numpy.int32(fila_mat_a), \n",
        "        numpy.int32(colum_mat_b), \n",
        "        numpy.int32(colum_mat_a), \n",
        "        matriz_a_Gpu, \n",
        "        matriz_b_Gpu, \n",
        "        matriz_c_Gpu, \n",
        "        block=( dim_hilo_x, dim_hilo_y, 1 ), \n",
        "        grid=(dim_bloque_x, dim_bloque_y,1) )\n",
        "\n",
        "tiempo_multiplicacion_paralela = datetime.now() - tiempo_multiplicacion_paralela\n",
        "\n",
        "# GPU - Copio el resultado desde la memoria GPU.\n",
        "cuda.memcpy_dtoh( matriz_c, matriz_c_Gpu )\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "print(\"Matiz A:\\n\", matriz_a)\n",
        "print(\"Matiz B:\\n\", matriz_b)\n",
        "print(\"Matiz C Secuencial:\\n\", matriz_c_secuencial)\n",
        "print(\"Matiz C Paralela:\\n\", matriz_c)\n",
        "print(\"Matiz C Paralela:\\n\", matriz_c)\n",
        "print(\"Tiempo TOTAL: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo GPU  : \", tiempo_en_ms( tiempo_multiplicacion_paralela ), \"[ms]\" )\n",
        "print(\"Tiempo CPU  : \", tiempo_en_ms( tiempo_multiplicacion_secuencial ), \"[ms]\" )"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread: [ 16 , 19  ], Bloque : [ 16 , 14 ]\n",
            "Total de Thread: [ 256 , 266  ]  =  68096\n",
            "Matiz A:\n",
            " [[ 16   3   9 ...   0  11  -7]\n",
            " [-13 -18  -1 ...   4 -12  -7]\n",
            " [ 23  10 -28 ...  -8 -11  -3]\n",
            " ...\n",
            " [ -5   3   3 ...  -4   1  18]\n",
            " [ -3   0  -6 ...   2  -3  -4]\n",
            " [-16 -18   9 ... -15 -10   6]]\n",
            "Matiz B:\n",
            " [[  0 -20   0 ...   5  -2 -12]\n",
            " [-20  -3   6 ...  15   4  -3]\n",
            " [ -2  -7   0 ... -17   3  15]\n",
            " ...\n",
            " [ -5  -5   0 ...   9   9 -12]\n",
            " [ -7  -5  11 ...   0  16   7]\n",
            " [-25  -6 -19 ...   6  -6   3]]\n",
            "Matiz C Secuencial:\n",
            " [[ 1544  2443 -1319 ... -1589  -978 -2111]\n",
            " [ 1006  1761 -1308 ... -2460  -101   769]\n",
            " [ 1319 -1330  -352 ...  1156 -1162  1462]\n",
            " ...\n",
            " [   46   126  -237 ... -1745   952  -956]\n",
            " [  336    75  -562 ...   523   574   400]\n",
            " [  111  -801 -1542 ...   158 -1081   300]]\n",
            "Matiz C Paralela:\n",
            " [[ 1544  2443 -1319 ... -1589  -978 -2111]\n",
            " [ 1006  1761 -1308 ... -2460  -101   769]\n",
            " [ 1319 -1330  -352 ...  1156 -1162  1462]\n",
            " ...\n",
            " [   46   126  -237 ... -1745   952  -956]\n",
            " [  336    75  -562 ...   523   574   400]\n",
            " [  111  -801 -1542 ...   158 -1081   300]]\n",
            "Matiz C Paralela:\n",
            " [[ 1544  2443 -1319 ... -1589  -978 -2111]\n",
            " [ 1006  1761 -1308 ... -2460  -101   769]\n",
            " [ 1319 -1330  -352 ...  1156 -1162  1462]\n",
            " ...\n",
            " [   46   126  -237 ... -1745   952  -956]\n",
            " [  336    75  -562 ...   523   574   400]\n",
            " [  111  -801 -1542 ...   158 -1081   300]]\n",
            "Tiempo TOTAL:  19199.662 [ms]\n",
            "Tiempo GPU  :  0.167 [ms]\n",
            "Tiempo CPU  :  19183.044 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqAv4Gt7qRrh"
      },
      "source": [
        "---\n",
        "# 4 Tabla de pasos\n",
        "\n",
        "\n",
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  wget url_imagen       | Lectura de la direcciòn URL de la imagen (jpg) a procesar.\n",
        "CPU      | pip install pycuda    | Instala en el cuaderno los driver de CUDA para Python.\n",
        "CPU      |  matplotlib inline    | Macro de Colab para mostrar imagenes.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  Image.open()          | Abre el archivo de la imagen.\n",
        "CPU      |  numpy.asarray(imagen) | Convierte el formato comprimido JPG a RAW.\n",
        "CPU      |  numpy.empty_like(()   | Genera el array destino, que tendrá a la imagen resultado. \n",
        "**GPU**  |  cuda.mem_alloc()      | Reserva la memoria para las imagenes en GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copio los valores en crudo de las imagenes al GPU.\n",
        "CPU      |  SourceModule()        | Posee el còdigo del kernel.\n",
        "CPU      |  module.get_function() | convierte el texto del kernel en funcion de Python.\n",
        "CPU      |  dim_hilo_x, dim_hilo_y| Calcula las dimensiones para la ejecuciòn de 2D.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU, enviando los parametros.\n",
        "CPU      |  print()               | Informa los atributos de la imagen.\n",
        "CPU      | cuda.memcpy_dtoh()     | Copia desde la memoria GPU al CPU.\n",
        "CPU      |  plt.imshow            | Muestra la imagen original.\n",
        "CPU      |  plt.imshow            | Muestra la imagen resultado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtiz4_7bmaDe"
      },
      "source": [
        "---\n",
        "# 5 Conclusiones\n",
        "\n",
        "Las conclusiones son explicadas en clase..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufDYy0LPmbYH"
      },
      "source": [
        "---\n",
        "# 6 Bibliografía\n",
        "\n",
        "[1] MARKDOWN SYNTAX Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[2] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n",
        "\n",
        "[3] Tutorial Point Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[4] 2009, SINTESIS DIGITAL DE COLOR UTILIZANDO TONOS DE GRIS, ING. JESÚS GUSTAVO FLORES ERAÑA : [PDF](https://ninive.uaslp.mx/xmlui/bitstream/handle/i/2264/MCA1SDC00901.pdf?sequence=1&isAllowed=y)\n"
      ]
    }
  ]
}