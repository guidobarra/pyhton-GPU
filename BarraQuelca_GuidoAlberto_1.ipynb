{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BarraQuelca_GuidoAlberto_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guidobarra/pyhton-GPU/blob/main/BarraQuelca_GuidoAlberto_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoYPFWcielY3"
      },
      "source": [
        "# 1 Introducción\n",
        "\n",
        "El siguiente ejemplo se realizará la búsqueda de un elemento dentro de un array.\n",
        "En el mundo de la informática hay varios algoritmos de búsqueda como por ejemplo la búsqueda binaria en el cual los elementos del array deben estar ordenados para realizar el algoritmo, otro algoritmo es la búsqueda secuencial el más simple de todos. La búsqueda de un objeto o palabra es algo muy utilizado, un ejemplo es el algoritmo de búsqueda de Google, buscar una palabra o secuencia de caracteres dentro de un archivo, buscar claves dentro de una tabla de base de datos.\n",
        "\n",
        "EL objetivo es enseñar el funcionamiento del Lenguaje Python, CUDA y buscar un número dentro de un array. El ejemplo es ilustrativo para entender los multi hilos de la GPU de una dimensión y ver la performance utilizando la GPU y CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32YB71STfPcy"
      },
      "source": [
        "---\n",
        "# 2 Armado del ambiente\n",
        "Toma los parametros de cantidad de elementos del array y el numero que debe buscar, deja disponible al contexto de ejecuciòn del cuaderno colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcnL4UkAN7ub"
      },
      "source": [
        "#@title # 2.1 Parámetros de ejecución\n",
        "#@markdown ### Especifique las dimeciones de la matrices:\n",
        "\n",
        "try: \n",
        "  cant_element =  100000000#@param {type:\"integer\"}\n",
        "  encontrar_numero =  1000000000#@param {type:\"integer\"}\n",
        "except Exception as e:\n",
        "  print(\"Error de ingresar los parametros\")\n",
        "  print(\"Error debido a: \", e.__class__)\n",
        "  print(e)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-KdeQaNvHyx"
      },
      "source": [
        "---\n",
        "## 2.2 Validar las parametros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paAPWUM4vICC"
      },
      "source": [
        "\n",
        "if cant_element < 0 :\n",
        "  print(\"ERROR LA CANTIDAD DE ELEMENTOS NO PUEDE SER MENOR QUE CERO\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GLsQ34ysP4_"
      },
      "source": [
        "---\n",
        "## 2.3 Instala en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ropgS48tsRTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6771094-b59c-4a14-d806-956abcd8c964"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 8.7MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=621008 sha256=d51f101014ef7dea5a347020e89ebee1d7540ddf1d871e26190cd0ac7718eee5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=c8d1a0a1d99bf421b05cbf41b23b09d8fe9b81f9d539e66f7db5e5fea6243bb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt4Pea0Psrx_"
      },
      "source": [
        "---\n",
        "# 3 Desarrollo\n",
        "Ejecución del algoritmo de busqueda utilizando la CPU para el desarrollo en su forma secuencual y la GPU para el desarrollo en su forma paralela."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_aVKaSenO2w"
      },
      "source": [
        "## 3.1 Desarrollo Secuencial\n",
        "Ejecución del algoritmo de busqueda de forma secuencial utilizando la CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_uVXVJjz_Jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33deb35-baa8-4fc3-f7cb-fbf877a9577d"
      },
      "source": [
        "try:\n",
        "  %matplotlib inline\n",
        "  from datetime import datetime\n",
        "  tiempo_total = datetime.now()\n",
        "  import numpy\n",
        "\n",
        "  # --------------------------------------------\n",
        "  # Definición de función que transforma el tiempo en  milisegundos\n",
        "  tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "  # --------------------------------------------\n",
        "\n",
        "  tiempo_definicion_vector = datetime.now()\n",
        "\n",
        "  # CPU - Defino la memoria del vector de n elementos en cpu.\n",
        "  vector = numpy.array(range(-cant_element, cant_element, 2))\n",
        "  vector = vector.astype(numpy.int32())\n",
        "\n",
        "  tiempo_definicion_vector = datetime.now() - tiempo_definicion_vector\n",
        "\n",
        "  tiempo_find_secuencial = datetime.now()\n",
        "\n",
        "  position = -1\n",
        "  for i in range(cant_element):\n",
        "    if vector[i] == encontrar_numero:\n",
        "      position = i\n",
        "      break\n",
        "\n",
        "  tiempo_find_secuencial = datetime.now() - tiempo_find_secuencial\n",
        "\n",
        "  tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "  print(\"\\n**ENCONTRAR UN ELEMENTO DENTRO DE UN VECTOR UTILIZANDO LA CPU**\\n\")\n",
        "  print(\"Cantidad de elementos del vector: \", cant_element)\n",
        "  print(\"Numero a encontrar: \", encontrar_numero)\n",
        "  print(\"Vector: \\n\", vector)\n",
        "  if position == -1:\n",
        "    print(\"No se encontro el numero: \", encontrar_numero)\n",
        "  else:\n",
        "    print(\"Se encontro el numero: \", encontrar_numero)\n",
        "    print(\"Posicion dentro del vector es: \", position)\n",
        "\n",
        "  print(\"Tiempo de definicion del vector: \", tiempo_en_ms( tiempo_definicion_vector ), \"[ms]\" )\n",
        "  print(\"Tiempo CPU  : \", tiempo_en_ms( tiempo_find_secuencial ), \"[ms]\" )\n",
        "  print(\"Tiempo TOTAL: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "except Exception as e:\n",
        "  print(\"Oops Ocurrio una error!\")\n",
        "  print(\"Error debido a: \", e.__class__)\n",
        "  print(e)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "**ENCONTRAR UN ELEMENTO DENTRO DE UN VECTOR UTILIZANDO LA CPU**\n",
            "\n",
            "Cantidad de elementos del vector:  100000000\n",
            "Numero a encontrar:  1000000000\n",
            "Vector: \n",
            " [-100000000  -99999998  -99999996 ...   99999994   99999996   99999998]\n",
            "No se encontro el numero:  1000000000\n",
            "Tiempo de definicion del vector:  17484.785 [ms]\n",
            "Tiempo CPU  :  153227.442 [ms]\n",
            "Tiempo TOTAL:  170712.311 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZA0yi-cna9v"
      },
      "source": [
        "## 3.2 Desarrollo Paralelo\n",
        "Ejecución del algoritmo de busqueda de forma paralelo utilizando la GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uKxB-tPnmN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b526f5-8621-491c-a283-55c270fdead9"
      },
      "source": [
        "try:\n",
        "  %matplotlib inline\n",
        "  from datetime import datetime\n",
        "  tiempo_total = datetime.now()\n",
        "  \n",
        "  import numpy\n",
        "  import pycuda.driver as cuda\n",
        "  import pycuda.autoinit\n",
        "  from   pycuda.compiler import SourceModule\n",
        "  \n",
        "  # --------------------------------------------\n",
        "  # Definición de función que transforma el tiempo en  milisegundos\n",
        "  tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "  # --------------------------------------------\n",
        "  \n",
        "  tiempo_definicion_vector = datetime.now()\n",
        "  \n",
        "  # CPU - Defino la memoria del vector de n elementos en cpu.\n",
        "  vector = numpy.array(range(-cant_element, cant_element, 2))\n",
        "  vector = vector.astype(numpy.int32())\n",
        "  \n",
        "  # CPU - Defino la memoria del vector position_v de 1 elemento en cpu.\n",
        "  position_v    = numpy.random.randn(1)*0\n",
        "  position_v[0] = -1\n",
        "  position_v    = position_v.astype(numpy.int32())\n",
        "  \n",
        "  tiempo_definicion_vector = datetime.now() - tiempo_definicion_vector\n",
        "  \n",
        "  tiempo_reserva_memoria_GPU = datetime.now()\n",
        "  # CPU - reservo la memoria GPU.\n",
        "  vector_Gpu = cuda.mem_alloc(vector.nbytes)\n",
        "  position_v_Gpu = cuda.mem_alloc(position_v.nbytes)\n",
        "  tiempo_reserva_memoria_GPU = datetime.now() - tiempo_reserva_memoria_GPU\n",
        "  \n",
        "  tiempo_copia_memoria_GPU = datetime.now()\n",
        "  # GPU - Copio la memoria al GPU.\n",
        "  cuda.memcpy_htod(vector_Gpu, vector)\n",
        "  cuda.memcpy_htod(position_v_Gpu, position_v)\n",
        "  tiempo_copia_memoria_GPU = datetime.now() - tiempo_copia_memoria_GPU\n",
        "  \n",
        "  #CPU - Defino la funcion kernel que ejecutará en GPU\n",
        "  module = SourceModule(\"\"\"\n",
        "  __global__ void find(int tam, int number_find, int *vector, int *position)\n",
        "  {\n",
        "      // Calculo las coordenadas del Thread en dos dimensiones.\n",
        "      int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  \n",
        "      // Verifico que los Thread, esten dentro de las dimensiones del vector\n",
        "      if( idx < tam ) {\n",
        "        if (vector[idx] == number_find && position[0] == -1) {\n",
        "          position[0] = idx;\n",
        "        }\n",
        "      }\n",
        "  }\n",
        "  \n",
        "  \"\"\")\n",
        "  \n",
        "  # CPU - Genero la función kernel.\n",
        "  kernel = module.get_function(\"find\")\n",
        "  \n",
        "  # GPU - Ejecuta el kernel.\n",
        "  # TODO: Falta consultar limites del GPU, para armar las dimensiones correctamente.\n",
        "  dim_hilo = 256\n",
        "  dim_bloque = numpy.int( (cant_element+dim_hilo-1) / dim_hilo )\n",
        "  print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "  \n",
        "  tiempo_find_paralelo = datetime.now()\n",
        "  \n",
        "  kernel( numpy.int32(cant_element),\n",
        "          numpy.int32(encontrar_numero),\n",
        "          vector_Gpu,\n",
        "          position_v_Gpu,\n",
        "          block=( dim_hilo, 1, 1 ),\n",
        "          grid=(dim_bloque, 1,1) )\n",
        "  \n",
        "  tiempo_find_paralelo = datetime.now() - tiempo_find_paralelo\n",
        "  \n",
        "  # GPU - Copio el resultado desde la memoria GPU.\n",
        "  cuda.memcpy_dtoh( position_v, position_v_Gpu )\n",
        "  tiempo_total = datetime.now() - tiempo_total\n",
        "  \n",
        "  print(\"\\n**ENCONTRAR UN ELEMENTO DENTRO DE UN VECTOR UTILIZANDO LA GPU**\\n\")\n",
        "  print(\"Cantidad de elementos del vector: \", cant_element)\n",
        "  print(\"Numero a encontrar: \", encontrar_numero)\n",
        "  print(\"Vector: \\n\", vector)\n",
        "  if position == -1 or position_v[0] == -1:\n",
        "    print(\"No se encontro el numero: \", encontrar_numero)\n",
        "  else:\n",
        "    print(\"Se encontro el numero: \", encontrar_numero)\n",
        "    print(\"Posicion dentro del vector es: \", position_v[0])\n",
        "    print(\"Posicion dentro del vector es: \", position)\n",
        "\n",
        "  print(\"Tiempo de definicion del vector: \", tiempo_en_ms( tiempo_definicion_vector ), \"[ms]\" )\n",
        "  print(\"Tiempo de reserva del vector: \", tiempo_en_ms( tiempo_reserva_memoria_GPU ), \"[ms]\" )\n",
        "  print(\"Tiempo de copia del vector: \", tiempo_en_ms( tiempo_copia_memoria_GPU ), \"[ms]\" )\n",
        "  print(\"Tiempo GPU  : \", tiempo_en_ms( tiempo_find_paralelo ), \"[ms]\" )\n",
        "  print(\"Tiempo TOTAL: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "except Exception as e:\n",
        "  print(\"Oops Ocurrio una error!\")\n",
        "  print(\"Error debido a: \", e.__class__)\n",
        "  print(e)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread x:  256 , Bloque x: 390625\n",
            "\n",
            "**ENCONTRAR UN ELEMENTO DENTRO DE UN VECTOR UTILIZANDO LA GPU**\n",
            "\n",
            "Cantidad de elementos del vector:  100000000\n",
            "Numero a encontrar:  1000000000\n",
            "Vector: \n",
            " [-100000000  -99999998  -99999996 ...   99999994   99999996   99999998]\n",
            "No se encontro el numero:  1000000000\n",
            "Tiempo de definicion del vector:  17964.016 [ms]\n",
            "Tiempo de reserva del vector:  0.933 [ms]\n",
            "Tiempo de copia del vector:  85.178 [ms]\n",
            "Tiempo GPU  :  1.389 [ms]\n",
            "Tiempo TOTAL:  19287.799 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqAv4Gt7qRrh"
      },
      "source": [
        "---\n",
        "# 4 Tabla de pasos\n",
        "\n",
        "\n",
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      | pip install pycuda    | Instala en el cuaderno los driver de CUDA para Python.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  numpy.random(n)       | Crear una vector con numeros ramdoms de n elementos.\n",
        "CPU      |  ar.astype(np.int32()) | Convierte los elemementos del array ar en elementos de tipo int 32 bit.\n",
        "**GPU**  |  cuda.mem_alloc()      | Reserva la memoria para el vector en la GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copia los valores en crudo del vector al GPU.\n",
        "CPU      |  SourceModule()        | Posee el còdigo del kernel.\n",
        "CPU      |  module.get_function() | convierte el texto del kernel en funcion de Python.\n",
        "CPU      |  dim_hilo_x            | Calcula la dimension para la ejecuciòn de 1D.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU, enviando los parametros.\n",
        "CPU      |  print()               | Informa medieante un mensaje.\n",
        "CPU      | cuda.memcpy_dtoh()     | Copia desde la memoria GPU al CPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtiz4_7bmaDe"
      },
      "source": [
        "---\n",
        "# 5 Conclusiones\n",
        "Se hicieron varias pruebas con vectores de un tamaño pequeño (50 elementos), y con un tamaño grande (100000000 elementos). Se observó que para vectores pequeños el tiempo de ejecución de la forma secuencial utilizando la CPU y el tiempo de ejecución de la forma paralela utilizando la GPU, son aproximadamente iguales y en ocasiones el tiempo de ejecución total de la GPU es mayor que el tiempo de ejecución total de la CPU, parecería que no estaría mejorando el tiempo de ejecución utilizando la GPU. Sin embargo al momento de tener vectores con muchos elementos se observó que el tiempo de ejecución de la búsqueda de un elemento utilizando la GPU se mantiene constante, aproximadamente, mientras que el tiempo de ejecución de la búsqueda de un elemento utilizando la CPU aumenta significativamente cada vez que aumenta la cantidad de elementos del vector. Se concluye que la utilización de la GPU baja el tiempo de ejecución de la búsqueda de un elemento en comparación con la CPU siempre que se tiene un vector de tamaño considerable por ejemplo 1000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufDYy0LPmbYH"
      },
      "source": [
        "---\n",
        "# 6 Bibliografía\n",
        "\n",
        "[1] Desarrollo Teorico algoritmo de busqueda: [Pagina Wiki](https://es.wikipedia.org/wiki/Algoritmo_de_b%C3%BAsqueda#:~:text=Un%20algoritmo%20de%20b%C3%BAsqueda%20es,en%20una%20partida%20de%20ajedrez.)\n",
        "\n",
        "[2] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n",
        "\n",
        "[3] Algoritmo de Busqueda y Ordenamiento: [PDF](https://www.inf.utfsm.cl/~noell/IWI-131-p1/Tema8b.pdf)\n"
      ]
    }
  ]
}