{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BarraQuelca_GuidoAlberto_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guidobarra/pyhton-GPU/blob/main/HPC/BarraQuelca_GuidoAlberto_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "# 1 Introducción\n",
        "\n",
        "El siguiente ejemplo se realizara la **Adición Matricial** A y B, el resultado de la Adición se guardara en la matriz C.\n",
        "Hay varias definiciones de Adición Matricial, por mencionar algunos:\n",
        "\n",
        "**Suma:** denotada por el signo +, suma el componente de la matriz A y el componente de la matriz B y el resultado de esta suma es un componente de la matriz C. Realiza la suma componente a componente de las matrices.\n",
        "\n",
        "**Suma Directa**: denotada por ⊕, no suma componente a componente como la Suma, sino que ambas matrices conviven en una matriz C de mayor dimensión que la matrices A Y B. Cada componente de la diagonal principal de la matriz C es una matriz, el resto de los componentes tiene ceros. Esta definición de Adición no necesita que sus matrices tengan las mismas dimensiones.\n",
        "\n",
        "En este ejemplo se realizará la Adición Matricial de **Suma**, la cual es la más conocida y más utilizada. Como se explicó antes la Adición Matricial de **Suma** realiza la suma componente a componente de las matrices, además de esto las matrices deben tener las mismas dimensiones, si las dimensiones no son igual no se puede realizar la **Suma**\n",
        "\n",
        "El desarrollo teórico de la **Suma** de matrices se mostrará a continuación. Realiza la suma componente a componente de las matrices\n",
        "\n",
        "\\begin{aligned}\\mathbf {A} +\\mathbf {B} &={\\begin{bmatrix}a_{11}&a_{12}&\\cdots &a_{1n}\\\\a_{21}&a_{22}&\\cdots &a_{2n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\a_{m1}&a_{m2}&\\cdots &a_{mn}\\\\\\end{bmatrix}}+{\\begin{bmatrix}b_{11}&b_{12}&\\cdots &b_{1n}\\\\b_{21}&b_{22}&\\cdots &b_{2n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\b_{m1}&b_{m2}&\\cdots &b_{mn}\\\\\\end{bmatrix}}\\\\&={\\begin{bmatrix}a_{11}+b_{11}&a_{12}+b_{12}&\\cdots &a_{1n}+b_{1n}\\\\a_{21}+b_{21}&a_{22}+b_{22}&\\cdots &a_{2n}+b_{2n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\a_{m1}+b_{m1}&a_{m2}+b_{m2}&\\cdots &a_{mn}+b_{mn}\\\\\\end{bmatrix}}\\\\\\end{aligned}\n",
        "\n",
        "\n",
        "La condición para poder realizar la suma de matrices es que la cantidad de filas de la matriz A tiene que ser igual a la cantidad de filas de la matriz B, y además cantidad de columnas de la matriz A tiene que ser igual a la cantidad de columnas de la matriz B, en la imagen de arriba se ve como la matriz A y B cumple con esta condición.\n",
        "\n",
        "EL objetivo es enseñar el funcionamiento del Lenguaje Python, C++, OpenMP, modulo Threading y el manejo de la operación de matriz a bajo nivel. El ejemplo es ilustrativo para entender y utilizar los Core que tiene un procesador, realizar proceso en paralelo y sacar conclusiones de la biblioteca OpenMP y el modulo Threading, programando un código que se va a realizar de forma paralela en los Core del procesador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "# 2 Armado del ambiente\n",
        "Armar el ambiente para ejecutar el algoritmo de suma de matrices con la biblioteca OpenMP y el modulo Threading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUGU9oaoHSm5"
      },
      "source": [
        "#@title # 2.1 Parámetros de ejecución para Threading\n",
        "#@markdown ### Especifique las dimensiones de la matrices:\n",
        "\n",
        "try: \n",
        "  tam_matriz =  12000#@param {type:\"integer\"}\n",
        "  alfa =  4#@param {type:\"integer\"}\n",
        "  beta =  2#@param {type:\"integer\"}\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"Error de ingresar los parametros\")\n",
        "  print(\"Error debido a: \", e.__class__)\n",
        "  print(e)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo1b0L5rGder"
      },
      "source": [
        "## 2.2 Crear archivo para OpenMP\n",
        "Se crea un archivo .cpp con el nombre de suma_matriz_axpy, este archivo contiene el codigo él cual ejecutará la suma de matrices de forma secuencial y tambien la suma de matrices de forma paralela utilizando los Core que tiene el procesador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJr_9dXGpJ05"
      },
      "source": [
        "# Codigo C++.\n",
        "code = \"\"\"\n",
        "// Axpy con OpenMP, usando C++, ejecutado en Colab. \n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cstdlib>\n",
        "#include <sys/time.h>\n",
        "#include <omp.h>    // Cabecera OpenMP   \n",
        "\n",
        "// ----------------------------------------------------------------------------\n",
        "// Macros que miden el tiempo.\n",
        "\n",
        "static double dHashTiempoHistory[3];\n",
        "static struct timeval tv;\n",
        "\n",
        "#define TIEMPO_INI( h )      \\\n",
        "   gettimeofday(&tv,NULL);   \\\n",
        "   dHashTiempoHistory[ h ] = tv.tv_sec + tv.tv_usec/1000000.0;\n",
        "   \n",
        "   \n",
        "#define TIEMPO_FIN( h )      \\\n",
        "   gettimeofday(&tv,NULL);   \\\n",
        "   dHashTiempoHistory[ h ] = ((tv.tv_sec + tv.tv_usec/1000000.0) - dHashTiempoHistory[ h ]) * 1000; // Devuelvo en milisegundos\n",
        "#define TIEMPO_GET( h ) dHashTiempoHistory[ h ]\n",
        "\n",
        "#define HTH_TOTAL         1\n",
        "#define HTH_AXPY_SEC      2\n",
        "#define HTH_AXPY_OMP      3\n",
        "\n",
        "// ----------------------------------------------------------------------------\n",
        "\n",
        "int main(int argc, char* argv[]) \n",
        "{ \n",
        "  TIEMPO_INI( HTH_TOTAL )\n",
        "\n",
        "  // validar parametros.\n",
        "  if( argc != 4 )\n",
        "  {\n",
        "    std::cout<<argv[1]<<std::endl;\n",
        "    std::cout<<argv[2]<<std::endl;\n",
        "    std::cout<<argv[3]<<std::endl;\n",
        "    std::cerr<< \" Error en los parametros, los cantidad de parametros deben ser 3:\"<<std::endl<<\" (alfa), (beta), (Tamaño de la matriz cantidad_N).\"<<argc<<std::endl;\n",
        "    exit( -1 );\n",
        "  }\n",
        "\n",
        "  // Obtener parametros\n",
        "  float alfa     = atof( argv[1] );\n",
        "  float beta     = atoi( argv[2] );\n",
        "  int cantidad_N = atoi( argv[3] );\n",
        "  \n",
        "  // Defino la memoria de las Matriz A, B y C. Inicializo con unos la matriz A y con el numero dos la matriz B\n",
        "  std::vector<std::vector<double>> matriz_A(cantidad_N, std::vector<double> (cantidad_N, 1));\n",
        "  std::vector<std::vector<double>> matriz_B(cantidad_N, std::vector<double> (cantidad_N, 2));\n",
        "  std::vector<std::vector<double>> matriz_C_secuencial(cantidad_N, std::vector<double> (cantidad_N, 0));\n",
        "  std::vector<std::vector<double>> matriz_C_paralela(cantidad_N, std::vector<double> (cantidad_N, 0));\n",
        "\n",
        "  // Realizo la función Axpy en forma secuencial.\n",
        "\n",
        "  TIEMPO_INI( HTH_AXPY_SEC )\n",
        "\n",
        "  for (int i=0;i<cantidad_N;i++)\n",
        "  {\n",
        "    for (int j=0;j<cantidad_N;j++)\n",
        "    {\n",
        "      matriz_C_secuencial[i][j] = alfa*matriz_A[i][j] + beta*matriz_B[i][j];\n",
        "    }\n",
        "  }\n",
        "\n",
        "  TIEMPO_FIN( HTH_AXPY_SEC )\n",
        "\n",
        "\n",
        "  // Realizo la función Axpy con OpenMP, paralela.\n",
        "\n",
        "  TIEMPO_INI( HTH_AXPY_OMP )\n",
        "\n",
        "  for (int i=0;i<cantidad_N;i++)\n",
        "  {  \n",
        "    #pragma omp parallel for  \n",
        "    for (int j=0;j<cantidad_N;j++)\n",
        "    {\n",
        "      matriz_C_paralela[i][j] = alfa*matriz_A[i][j] + beta*matriz_B[i][j];\n",
        "    }\n",
        "  }\n",
        "\n",
        "  TIEMPO_FIN( HTH_AXPY_OMP )\n",
        "\n",
        "  // --------------------------------------------\n",
        "  // Muestro los resultados.\n",
        "  /*\n",
        "  std::cout<<\" matriz paralela :\"<<std::endl;\n",
        "  std::cout<<\"[\"; \n",
        "  for(int i=0;i<cantidad_N;i++)\n",
        "  {\n",
        "    for(int c=0;c<cantidad_N;c++)\n",
        "    {\n",
        "      std::cout<<matriz_C_paralela[i][c]<< \", \";\n",
        "    }\n",
        "    std::cout<<std::endl;\n",
        "  }\n",
        "  std::cout<<\"]\"<<std::endl<<std::endl; \n",
        "\n",
        "  std::cout<<\" matriz secuencial :\"<<std::endl;\n",
        "  std::cout<<\"[\"; \n",
        "  for(int i=0;i<cantidad_N;i++)\n",
        "  {\n",
        "    for(int c=0;c<cantidad_N;c++)\n",
        "    {\n",
        "      std::cout<<matriz_C_secuencial[i][c]<< \", \";\n",
        "    }\n",
        "    std::cout<<std::endl;\n",
        "  }\n",
        "  std::cout<<\"]\"<<std::endl; \n",
        "  */\n",
        "\n",
        "  TIEMPO_FIN( HTH_TOTAL )\n",
        "\n",
        " std::cout<<\"EJERCICIO DE SUMA DE MATRICES\"<<std::endl;\n",
        " std::cout<<\"C = alfa*A + beta*B\"<<std::endl;\n",
        " std::cout<<\"se realizo \"<<cantidad_N*cantidad_N<<\" operaciones de suma\"<<std::endl;\n",
        " std::cout<<\"Valor ALFA       : \"<<alfa<<std::endl;\n",
        " std::cout<<\"Valor BETA       : \"<<beta<<std::endl;\n",
        " std::cout<<\"MATRIZ CUADRADA  : \"<<cantidad_N<<std::endl; \n",
        " std::cout<<\"Valores Reales   : \"<<std::endl;\n",
        " std::cout<<\"Tiempo TOTAL     : \"<<TIEMPO_GET(HTH_TOTAL   )<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Sec  : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Omp  : \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<std::endl;\n",
        " std::cout<<\"SpeedUp          : (tiempo Secuencial/tiempo paralelo) : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" / \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Eficiencia       : SpeedUp/nro procesadores            : \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<\" / \"<<omp_get_num_procs()<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))<<std::endl;\n",
        " std::cout<<\"Coste Sec        : nro procesadores*Tiempo             : \"<<1<<\" * \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        " std::cout<<\"Coste Omp        : nro procesadores*Tiempo             : \"<<omp_get_num_procs()<<\" * \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Funcion Overhead : Coste Omp - tiempo Secuencial       : \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<\" - \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))-TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        "\n",
        "\n",
        " std::cout<<std::endl;\n",
        " std::cout<<\"Valores Ideal: \"<<std::endl;\n",
        " TIEMPO_GET(HTH_AXPY_OMP) = TIEMPO_GET(HTH_AXPY_SEC) / 2;\n",
        " std::cout<<\"Tiempo axpy Sec  : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" [ms]\"<<std::endl;\n",
        " std::cout<<\"Tiempo axpy Omp  : \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" [ms]\"<<std::endl;\n",
        "\n",
        " std::cout<<\"SpeedUp          : (tiempo Secuencial/tiempo paralelo) : \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" / \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Eficiencia       : SpeedUp/nro procesadores            : \"<<TIEMPO_GET(HTH_AXPY_SEC)/TIEMPO_GET(HTH_AXPY_OMP)<<\" / \"<<omp_get_num_procs()<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)/(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))<<std::endl;\n",
        " std::cout<<\"Coste Sec        : nro procesadores*Tiempo             : \"<<1<<\" * \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        " std::cout<<\"Coste Omp        : nro procesadores*Tiempo             : \"<<omp_get_num_procs()<<\" * \"<<TIEMPO_GET(HTH_AXPY_OMP)<<\" = \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<std::endl;\n",
        " std::cout<<\"Funcion Overhead : Coste Omp - tiempo Secuencial       : \"<<omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP)<<\" - \"<<TIEMPO_GET(HTH_AXPY_SEC)<<\" = \"<<(omp_get_num_procs()*TIEMPO_GET(HTH_AXPY_OMP))-TIEMPO_GET(HTH_AXPY_SEC)<<std::endl;\n",
        "\n",
        "\n",
        "}\n",
        "// ----------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"\n",
        "text_file = open(\"suma_matriz_axpy.cpp\", \"w\")\n",
        "text_file.write(code)\n",
        "text_file.close()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "## 2.3 Compila el codigo de C++."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gE-Ez1qtyIA"
      },
      "source": [
        "!g++ -o suma_matriz -fopenmp suma_matriz_axpy.cpp"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "# 3 Desarrollo\n",
        "Ejecución del programa con OpenMP y Threading de python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my2uxMLFRM0Z"
      },
      "source": [
        "## 3.1 Desarrollo OpenMP\n",
        "\n",
        "Ejecución del programa que realiza la suma de matrices utilizando OpenMP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiSh8sKbsX_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4120ea56-4023-43d8-83b3-f7a2e0178039"
      },
      "source": [
        "try:\n",
        "  #numero de hilos en OpemMP\n",
        "  %env OMP_NUM_THREADS=2\n",
        "\n",
        "  #param uno : alfa\n",
        "  #param dos : beta\n",
        "  #param tres: tamaño de la matriz\n",
        "\n",
        "  #ejecutar programa\n",
        "  !./suma_matriz 4 2 12000\n",
        "except Exception as e:\n",
        "  print(\"Oops Ocurrio una error!\")\n",
        "  print(\"Error debido a: \", e.__class__)\n",
        "  print(e)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: OMP_NUM_THREADS=2\n",
            "EJERCICIO DE SUMA DE MATRICES\n",
            "C = alfa*A + beta*B\n",
            "se realizo 144000000 operaciones de suma\n",
            "Valor ALFA       : 4\n",
            "Valor BETA       : 2\n",
            "MATRIZ CUADRADA  : 12000\n",
            "Valores Reales   : \n",
            "Tiempo TOTAL     : 8630.45 [ms]\n",
            "Tiempo axpy Sec  : 2545.03 [ms]\n",
            "Tiempo axpy Omp  : 2269.8 [ms]\n",
            "\n",
            "SpeedUp          : (tiempo Secuencial/tiempo paralelo) : 2545.03 / 2269.8 = 1.12126\n",
            "Eficiencia       : SpeedUp/nro procesadores            : 1.12126 / 2 = 0.560628\n",
            "Coste Sec        : nro procesadores*Tiempo             : 1 * 2545.03 = 2545.03\n",
            "Coste Omp        : nro procesadores*Tiempo             : 2 * 2269.8 = 4539.61\n",
            "Funcion Overhead : Coste Omp - tiempo Secuencial       : 4539.61 - 2545.03 = 1994.58\n",
            "\n",
            "Valores Ideal: \n",
            "Tiempo axpy Sec  : 2545.03 [ms]\n",
            "Tiempo axpy Omp  : 1272.52 [ms]\n",
            "SpeedUp          : (tiempo Secuencial/tiempo paralelo) : 2545.03 / 1272.52 = 2\n",
            "Eficiencia       : SpeedUp/nro procesadores            : 2 / 2 = 1\n",
            "Coste Sec        : nro procesadores*Tiempo             : 1 * 2545.03 = 2545.03\n",
            "Coste Omp        : nro procesadores*Tiempo             : 2 * 1272.52 = 2545.03\n",
            "Funcion Overhead : Coste Omp - tiempo Secuencial       : 2545.03 - 2545.03 = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHBWan5J5ieB"
      },
      "source": [
        "## 3.2 Desarrollo Threading\n",
        "\n",
        "Ejecución del programa que realiza la suma de matrices utilizando el modulo threading de python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvoatw3r5i3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0084e8-97b9-45eb-f432-1c2bd36450df"
      },
      "source": [
        "try:\n",
        "  import numpy as np\n",
        "  import threading\n",
        "  from datetime import datetime\n",
        "\n",
        "  # --------------------------------------------\n",
        "  # Definición de función que transforma el tiempo en  milisegundos \n",
        "  tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "  # --------------------------------------------\n",
        "\n",
        "\n",
        "  #Defino funciones\n",
        "\n",
        "  #Suma elemento a elemento de la matriz\n",
        "  def sumaElemento(a, b, c, alfa, beta, fila):\n",
        "    c[fila] = alfa*a + beta*b\n",
        "  \n",
        "  #Suma de matrices utilizando tam hilos\n",
        "  def sumaMatrizParelela(matriz_a, matriz_b, tam, alfa, beta, func=sumaElemento):\n",
        "  \n",
        "    #definir matriz resultado\n",
        "    matriz_c_paralela = np.zeros((tam, tam), dtype=int)\n",
        "\n",
        "    #array de hilos\n",
        "    threads = []\n",
        "\n",
        "    for i in range(tam):\n",
        "      #configuracion de hilo, funcion a ejecutar y parametros de la funcion\n",
        "      th = threading.Thread(target=func, \n",
        "                            args=(matriz_a[i], \n",
        "                                  matriz_b[i],\n",
        "                                  matriz_c_paralela,\n",
        "                                  alfa,\n",
        "                                  beta,\n",
        "                                  i)\n",
        "                            )\n",
        "      #ejecutar hilo\n",
        "      th.start()\n",
        "      #guardar hilo en array\n",
        "      threads.append(th)\n",
        "  \n",
        "    #espero a que termine todos los hilos\n",
        "    for th in threads:\n",
        "        th.join()\n",
        "\n",
        "    #retorno matriz resulado\n",
        "    return matriz_c_paralela\n",
        "  \n",
        "  def sumaMatrizSecuencial(matriz_a, matriz_b, tam, alfa, beta):\n",
        "    matriz_c_secuencial = np.zeros((tam, tam), dtype=int)\n",
        "    for i in range(tam):\n",
        "      for j in range(tam):\n",
        "        matriz_c_secuencial[i][j] = alfa*matriz_a[i][j] + beta*matriz_b[i][j]\n",
        "\n",
        "    return matriz_c_secuencial\n",
        "  \n",
        "  if __name__ == '__main__':\n",
        "         \n",
        "    cant = tam_matriz\n",
        "\n",
        "    tiempo_definicion_matrices = datetime.now()\n",
        "    #defino matrices A, B\n",
        "    a = np.ones((cant, cant), dtype=int)\n",
        "    b = np.ones((cant, cant), dtype=int)*2\n",
        "    tiempo_definicion_matrices = datetime.now() - tiempo_definicion_matrices\n",
        "\n",
        "    #ejecutar suma secuencial y obtener el tiempo de la ejecucion\n",
        "    tiempo_suma_secuencial = datetime.now()\n",
        "    matriz_c_secuencial = sumaMatrizSecuencial(a, b, cant, alfa, beta)\n",
        "    tiempo_suma_secuencial = datetime.now() - tiempo_suma_secuencial\n",
        "\n",
        "    #ejecutar suma paralela y obtener el tiempo de la ejecucion\n",
        "    tiempo_suma_paralela = datetime.now()\n",
        "    matriz_c_paralela = sumaMatrizParelela(a, b, cant, alfa, beta)\n",
        "    tiempo_suma_paralela = datetime.now() - tiempo_suma_paralela\n",
        "\n",
        "    print(\"\\nEJERCICIO DE SUMA DE MATRICES\")\n",
        "    print(\"C = alfa*A + beta*B\")\n",
        "    print('Se ejecuto {} jobs/hilos en paralelo'.format(cant))\n",
        "    print('Se realizo {} operaciones de suma'.format(cant*cant))\n",
        "    print(\"Valor ALFA       : \", alfa)\n",
        "    print(\"Valor BETA       : \", beta)\n",
        "    print(\"MATRIZ CUADRADA  : \", cant)\n",
        "    print(\"Tiempo de definicion de matrices: \", tiempo_en_ms( tiempo_definicion_matrices ), \"[ms]\" )\n",
        "    print(\"Tiempo suma secuencial: \", tiempo_en_ms( tiempo_suma_secuencial ), \"[ms]\" )\n",
        "    print(\"Tiempo suma paralela: \", tiempo_en_ms( tiempo_suma_paralela ), \"[ms]\" )\n",
        "    print(\"Matiz A:\\n\", a)\n",
        "    print(\"Matiz B:\\n\", b)\n",
        "    print(\"Matiz secuencial C:\\n\", matriz_c_secuencial)\n",
        "    print(\"Matiz paralela C:\\n\", matriz_c_paralela)\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"Oops Ocurrio una error!\")\n",
        "  print(\"Error debido a: \", e.__class__)\n",
        "  print(e)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EJERCICIO DE SUMA DE MATRICES\n",
            "C = alfa*A + beta*B\n",
            "Se ejecuto 12000 jobs/hilos en paralelo\n",
            "Se realizo 144000000 operaciones de suma\n",
            "Valor ALFA       :  4\n",
            "Valor BETA       :  2\n",
            "MATRIZ CUADRADA  :  12000\n",
            "Tiempo de definicion de matrices:  1851.8519999999999 [ms]\n",
            "Tiempo suma secuencial:  204734.576 [ms]\n",
            "Tiempo suma paralela:  4346.156 [ms]\n",
            "Matiz A:\n",
            " [[1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " ...\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]]\n",
            "Matiz B:\n",
            " [[2 2 2 ... 2 2 2]\n",
            " [2 2 2 ... 2 2 2]\n",
            " [2 2 2 ... 2 2 2]\n",
            " ...\n",
            " [2 2 2 ... 2 2 2]\n",
            " [2 2 2 ... 2 2 2]\n",
            " [2 2 2 ... 2 2 2]]\n",
            "Matiz secuencial C:\n",
            " [[8 8 8 ... 8 8 8]\n",
            " [8 8 8 ... 8 8 8]\n",
            " [8 8 8 ... 8 8 8]\n",
            " ...\n",
            " [8 8 8 ... 8 8 8]\n",
            " [8 8 8 ... 8 8 8]\n",
            " [8 8 8 ... 8 8 8]]\n",
            "Matiz paralela C:\n",
            " [[8 8 8 ... 8 8 8]\n",
            " [8 8 8 ... 8 8 8]\n",
            " [8 8 8 ... 8 8 8]\n",
            " ...\n",
            " [8 8 8 ... 8 8 8]\n",
            " [8 8 8 ... 8 8 8]\n",
            " [8 8 8 ... 8 8 8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "---\n",
        "# 4 Tabla de pasos\n",
        "\n",
        "\n",
        " Procesador | lengueaje   | Funciòn \t\t\t\t\t   | Detalle\n",
        "------------|----------   |--------------------------------|----------------\n",
        "CPU         | Python      |  open()                        | Abrir un archivo para escritura\n",
        "CPU         | Python      |  write()                       | Escribir el archivo\n",
        "CPU         | Python      |  close()                       | Cerrar el archivo\n",
        "CPU   \t    | Python      |  !g++ -o obj -fopenmp c.cpp    | Compilar el archivo .cpp, y crear ejectable\n",
        "CPU         | Python      |  %env OMP_NUM_THREADS=n        | Cantidad de threads n\n",
        "CPU         | Python      |  !./suma_matriz 2 5 18000      | Ejecutar el programa openMP\n",
        "CPU         | C++         |  TIEMPO_INI()                  | Inicio del tiempo\n",
        "CPU         | C++         |  TIEMPO_FIN()                  | Finaliza el tiempo\n",
        "CPU         | C++         |  TIEMPO_GET()                  | Obtener el tiempo guardado\n",
        "CPU         | C++, openMP |  omp_get_num_procs()           | Obtener la cantidad de procesadores\n",
        "CPU         | C++, openMP |  omp_get_thread_num()          | Obtener numero del hilo\n",
        "CPU\t\t      | C++, openMP |  #pragma omp parallel for      | Crear los hilos en base a la sentencia for\n",
        "CPU         | Python      |  import                        | Importa los módulos\n",
        "CPU         | Python      |  datetime.now()                | Toma el tiempo actual\n",
        "CPU         | Python      |  datetime.now()                | Toma el tiempo actual\n",
        "CPU         | Python      |  print()                       | Informa con algun mensaje\n",
        "CPU         | Python      |  print()                       | Informa con algun mensaje\n",
        "CPU         |Python, numpy|  np.zeros()                    | Crear una matriz de ceros\n",
        "CPU         |Python, numpy|  np.ones()                     | Crear una matriz de unos\n",
        "CPU         |Python, Threading| threading.Thread()             | Configuracion de hilo\n",
        "CPU         |Python, Threading|  th.start()                    | Ejecutar de hilo\n",
        "CPU         |Python, Threading|  th.join()                     | Espera los hilos hasta que termine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ9i7KaUsHm6"
      },
      "source": [
        "#5 Conclusiones\n",
        "\n",
        "Se realizaron varias pruebas con matrices de distintos tamaños. Colab nos brinda un procesador y una memoria fijas, el cual nos limita al momento de realizar las pruebas, un ejemplo de esto es que no se puede probar matrices mayores a 18000x18000, debido a que se llena la menoria que nos ofrece Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSQCSCTsR9n1"
      },
      "source": [
        "## 5.1 Conclusion de OpenMP\n",
        "\n",
        "Se hicieron varias pruebas modificando el tamaño de las matrices y los hilos, para este caso la cantidad de hilos es independiente del tamaño de la matrices.\n",
        "\n",
        "**Pruebas con Cantidad_N<1000:** En estas pruebas se observó que el tiempo de ejecución para la suma de matrices son aproximadamente igual para Cantidad_N = 1000, tanto para la forma secuencial, como para la forma paralela que utiliza los Core del procesador. Al disminuir la Cantidad_N el tiempo de ejecución de la forma secuencial es mejor que el tiempo de ejecución de la forma paralela esto es debido a que openMP utiliza hilos, la creación de los hilos y su cambio de contexto hacen que el tiempo que ejecución del algoritmo aumente.\n",
        "\n",
        "**Pruebas con Cantidad_N>1000:** En estas pruebas se observo que el tiempo de ejecución para la suma de matrices son distintos, al utilizar los Core del procesador se observa que hay una mejora en la eficiencia y el tiempo es menor, en comparación con la forma secuencial.\n",
        "\n",
        "**Pruebas variando la cantidad de hilos:** En esta prueba se observo un baja significativa de la performance del 30% o mayor, en comparación con la forma secuencial, al aumentar la cantidad de hilos el tiempo de ejecución de la forma paralela aumenta, esto es debido a que el tiempo de creación de los hilos y su cambio de contexto impacta en el tiempo total, si bien openMP mejora y reduce el tiempo de creacion y cambio de contexto de los hilos, al tener varios hilos el tiempo aumenta.\n",
        "\n",
        "Se concluye que la cantidad de elementos, los hilos y los Core del procesador son factores que influyen en el tiempo de ejecución del algoritmo. Estos tres factores son importantes y hay que tenerlos en cuenta debido a que el tiempo de ejecución utilizando openMP es peor que la ejecución secuencial si se tiene un conjunto pequeño de elementos a procesar o si se tiene muchos hilos con un procesador que tiene pocos Core. Para un conjunto grande de elementos y una cantidad de hilos acorde a la cantidad de Core del procesador el tiempo que ejecución del algoritmo utilizando openMP es mejor que el tiempo de ejecución secuencial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf1NFsw4SMms"
      },
      "source": [
        "## 5.2 Conclusion de Threading\n",
        "\n",
        "Se hicieron varias pruebas modificando el tamaño de las matrices y los hilos, para este caso la cantidad de hilos es dependiente de la cantidad de filas de la matrices siendo la cantidad de hilos igual a la cantidad de filas de la matrices.\n",
        "\n",
        "**Pruebas con Cantidad_N<80:** En estas pruebas se observó que el tiempo de ejecución para la suma de matrices son aproximadamente igual para Cantidad_N = 80, tanto para la forma secuencial, como para la forma paralela que utiliza el modulo Threading de python. Al disminuir la Cantidad_N el tiempo de ejecución de la forma secuencial es mejor que el tiempo de ejecución de la forma paralela utilizando los hilos de Threading, esto es debido al tiempo de creación de los hilos y su cambio de contexto.\n",
        "\n",
        "**Pruebas con Cantidad_N>80:** En estas pruebas se observo que el tiempo de ejecución para la suma de matrices son distintos, al utilizar los hilos con el modulo Threading, se observa que hay una mejora en la eficiencia y el tiempo de ejecución es menor, en comparación con la forma secuencial de python. Cabe destacar que al tener una cantidad de hilos mayor, debido a que aumenta el tamaño de la matriz, el tiempo de ejecucion de la forma paralela sigue siendo mejor que el tiempo secuncial apesar del tiempo de creación de los hilos y su cambio de contexto.\n",
        "\n",
        "Se concluye que la cantidad de elementos, los hilos y los Core del procesador son factores que influyen en el tiempo de ejecución del algoritmo. Estos tres factores son importantes y hay que tenerlos en cuenta debido a que el tiempo de ejecución utilizando el modulo Threading es peor que la ejecución secuencial si se tiene un conjunto pequeño de elementos a procesar. Para un conjunto grande de elementos el tiempo que ejecución del algoritmo utilizando el modulo Threading es mejor que el tiempo de ejecución secuencial.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz0_nI73SjMg"
      },
      "source": [
        "## 5.3 Conclusion final\n",
        "\n",
        "Se hizo el mismo ejercicios tanto de forma secuencial como de forma paralela utilizando OpenMP y el modulo Threading.\n",
        "\n",
        "Si comparamos el tiempo de ejecución de la forma paralela de OpenMP y Threading, se observa que el tiempo de ejecucion con OpenMP es mejor que el tiempo de ejecucion con el modulo Threading, esto es debido a que con OpenMP la catidad de hilos es independiente del tamaño de la matriz, haciendo que una conjunto pequeños de hilos realicen la suma de la matriz lo que conlleva a tener un menor tiempo en la creacion de hilos y cambio de contexto, miestras que con el modulo Threading la cantidad de hilos aumenta si el tamaño de la matriz aumenta lo que conlleva a tener un mayor tiempo en la creacion de hilos y cambio de contexto en compracion con OpenMP.\n",
        "\n",
        "OpenMP nos brinda una facilidad al momento de programar los hilos, mediante etiquetas, en compracion con el modulo Threading de python el cual se debe configurar de el hilo, ejecutarlo y/o esperar al hilo, si el ejercicio lo requiere, esto implica una dificultad al momento de programar. Ademas con OpenMP la cantidad de hilos es independiente de la programacion del codigo, mientras que con el modulo de Threading la cantidad de hilos es dependiente de la programacion del codigo. \n",
        "\n",
        "Para avansar con el proyecto y reducir el tiempo de ejecucion del algoritmo se puede optar por aplicar tecnicas de programacion que reduscan el tiempo de ejecucion, como por ejemplo no es necesario recorrer toda la matriz para realizar la suma elemento a elemento, se puede recorrer la mitad de la matriz dado que los sub indices nos dan otro elemento de la matriz. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOQYEPGtsPfL"
      },
      "source": [
        "---\n",
        "# 6 Bibliografía\n",
        "\n",
        "[1] Suma de matrices, conceptual: [Pagina economipedia](https://economipedia.com/definiciones/suma-de-matrices.html)\n",
        "\n",
        "[2] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n",
        "\n",
        "[3] Adicíon Matricial: [WIKI](https://es.wikipedia.org/wiki/Adici%C3%B3n_matricial)\n",
        "\n",
        "[4] OpenMP: [PDF](http://so-unlam.com.ar/material-clase/HPC/openmp-4.5.pdf)\n",
        "\n",
        "[5] MARKDOWN SYNTAX Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[6] Función Axpy de biblioteca BLAS: [Referencia](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-axpy.html)\n",
        "\n",
        "[7] Introducción al modulo Threading: [Referencia](https://realpython.com/intro-to-python-threading/)\n",
        "\n",
        "[8] Modulo Threading: [Referencia](https://docs.python.org/es/3/library/threading.html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}